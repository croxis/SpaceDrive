#version 440

#extension GL_ARB_shader_image_load_store : enable

// TODO: Make some benchmarks to see wheter unrolling
// is faster or slower ..

// NOTICE: This pass does DSSDO.
// For dssdo, this option is !!REQUIRED!!
// Otherwise it runs poor as f*ck
#pragma optionNV (unroll all)


// FILE: 'Shader/Includes/Configuration.include' 
// This is the main configuration file, included by almost all shaders

// Max values for the light culling
// If you change anything regarding this in LightManager,
// change it here, too
#define MAX_VISIBLE_LIGHTS 25
#define MAX_LIGHTS_PER_PATCH 63

// Same as in LightManager.py
#define MAX_POINT_LIGHTS 16
#define MAX_SHADOW_POINT_LIGHTS 16

// Max shadow maps. Has to be the same as in LightManager.py
#define SHADOW_MAX_TOTAL_MAPS 24


// Wheter to clear the lighting buffer each frame to be
// able to see changes in lighting - only recommended for debugging
#define LIGHTING_CLEAR_BUFFER_EACH_FRAME


// GLSL really needs this as a builtin!
#define saturate(v) clamp(v, 0, 1)

// Needed for light culling
const float sqrt_of_2 = 1.4142135623;

// Load Auto-Config

// FILE: 'Shader/Includes/AutoGeneratedConfig.include' 
// Autogenerated by RenderPipeline.py
// Do not edit! Your changes will be lost.

#define SMAA_PRESET_ULTRA
#define LIGHTING_COMPUTE_PATCH_SIZE_X 32
#define LIGHTING_COMPUTE_PATCH_SIZE_Y 32
#define LIGHTING_MIN_MAX_DEPTH_ACCURACY 1
#define LIGHTING_ANY_BOUND_CHECK 1
#define LIGHTING_ACCURATE_BOUND_CHECK 1
#define USE_SHADOWS 1
#define SHADOW_MAP_ATLAS_SIZE 8192
#define SHADOW_MAX_UPDATES_PER_FRAME 4
#define SHAODOW_GEOMETRY_MAX_VERTICES 12
#define SHADOWS_NUM_SAMPLES 16
#define USE_HARDWARE_PCF 1
#define WINDOW_WIDTH 1600
#define WINDOW_HEIGHT 900
#define USE_MOTION_BLUR 1
#define MOTION_BLUR_SAMPLES 12
#define DSSDO_ENABLED 1
#define DSSDO_NUM_SAMPLES 8
#define DSSDO_RADIUS 1.0
#define DSSDO_MAX_DISTANCE 4.0
#define DSSDO_MAX_ANGLE 0.4
#define DSSDO_STRENGTH 1.3
#define DEBUGGER_ACTIVE 1
#define DEBUG_RM_DEFAULT 1

// Performance functions

// FILE: 'Shader/Includes/Performance.include' 
vec4 FAST_mul(mat4 m, vec3 v) {
    return m * vec4(v, 1);
    // return v.x * m[0] + (v.y * m[1] + (v.z * m[2] + m[3] ));
}

vec4 FAST_mul_no_w(mat4 m, vec3 v) {
    return m * vec4(v, 0);
     // return v.x * m[0] + (v.y * m[1] + (v.z * m[2] ));
}


vec4 FAST_normalize_prefactor(vec4 v) {
    // todo
    return normalize(v);
}

// Wheter to use post-processing blur, this affects DSSDO
#define USE_OCCLUSION_BLUR



#define M_PI 3.14159265



// #pragma optionNV (unroll all)


#define USE_BINDLESS_TEXTURES 0

#if USE_BINDLESS_TEXTURES
    #define BINDLESS layout(bindless_sampler)
#else
    #define BINDLESS
#endif

// FILE: 'Shader/Includes/Light.include' 
struct Light {
    vec3 position;
    vec3 color;
    vec3 direction;
    int posterIndex;
    int lightType;
    float radius;
    int sourceIndexes[6];
};

// FILE: 'Shader/Includes/Material.include' 
// FILE: 'Shader/Includes/Packing.include' 
// http://aras-p.info/texts/CompactNormalStorage.html
// Packs a normal to a vec2
vec2 encodeNormal(vec3 n)
{
    // Prevents artifacts at surfaces which point to the bottom??
    n *= 0.999;

    float p = inversesqrt(n.z*8+8);
    return vec2(n.xy*p + 0.5);
}

// Unpacks a normal from a vec2
vec3 decodeNormal(vec2 encoded)
{
    vec2 fenc = encoded * 4.0 - 2.0;
    float f = dot(fenc,fenc);
    float g = sqrt(1.0 - f/4.0);
    vec3 n;
    n.xy = fenc * g;
    n.z = 1.0 - f/2.0;
    return n;
}

// // Packs float to 2 floats for more precision

// vec2 packDepth(float d) {
//     // return vec2(d, d);
//     return vec2(floor(d*1024), fract(d*1024));
// }

// // Unpacks 2 floats to one high precision float
// float unpackDepth(vec2 d) {
//     // return d.x;
//     return (d.x + d.y) / 1024.0;
// }

const float colorPackingFactor = 1.0 - (1.0 / 255.0);

vec2 packColor(vec3 color) {
    return vec2(color.x,
            saturate(color.y) * colorPackingFactor +
            ceil(color.z * 255.0)
        );
}

vec3 unpackColor(vec2 pack) {
    return vec3(pack.x, fract(pack.y), floor(pack.y) / 256.0 );
}


struct Material {
    vec3 baseColor;
    float roughness;
    float metallic;
    float specular;
    float transluency;
    vec3 position;
    vec3 normal;
};


Material unpackMaterial(vec4 data0, vec4 data1, vec4 data2) {
    Material m;

    m.position = data0.xyz;
    m.roughness = data0.w;
    m.normal = decodeNormal(data1.xy);
    m.baseColor = unpackColor(data1.zw);
    m.metallic = data2.w;
    m.specular = data2.z;
    // m.transluency = data2.z;

    m.transluency = 0.0;

    return m;
}

// FILE: 'Shader/Includes/ShadowSource.include' 
struct ShadowSource {
    int resolution;
    vec2 atlasPos;
    mat4 mvp;
    float nearPlane;
    float farPlane;
};

// FILE: 'Shader/Includes/ColorCorrection.include' 
// Instagram effect, yay! :D
vec3 convertColorSpace(vec3 x1) {
    vec3 x2 = x1 * x1;
    vec3 x3 = x2 * x1;
    vec3 x4 = x3 * x1;
    vec3 x5 = x4 * x1;
    vec3 result;

    result.r = 0.078619672271 +
        (0.95704630331)*x1.r +
        (1.67552722496)*x2.r +
        (-4.43954259306)*x3.r +
        (4.05428794615)*x4.r +
        (-1.37605047802)*x5.r;
    result.g = -0.00167123955185 +
        (0.671997329728)*x1.g +
        (3.09694633717)*x2.g +
        (-5.30948014199)*x3.g +
        (2.8547560319)*x4.g +
        (-0.312785174623)*x5.g;
    result.b = 0.0744127064858 +
        (0.928306646392)*x1.b +
        (0.940123058005)*x2.b +
        (-2.62632861258)*x3.b +
        (2.4523831772)*x4.b +
        (-0.858903293136)*x5.b;

    return saturate(result);
}

// FILE: 'Shader/Includes/DSSDO.include' 
// FILE: 'Shader/Includes/PoissonDisk.include' 
vec3 poisson3D_32[32] = vec3[](
    vec3(-0.134, 0.044, -0.825),
    vec3(0.045, -0.431, -0.529),
    vec3(-0.537, 0.195, -0.371),
    vec3(0.525, -0.397, 0.713),
    vec3(0.895, 0.302, 0.139),
    vec3(-0.613, -0.408, -0.141),
    vec3(0.307, 0.822, 0.169),
    vec3(-0.819, 0.037, -0.388),
    vec3(0.376, 0.009, 0.193),
    vec3(-0.006, -0.103, -0.035),
    vec3(0.098, 0.393, 0.019),
    vec3(0.542, -0.218, -0.593),
    vec3(0.526, -0.183, 0.424),
    vec3(-0.529, -0.178, 0.684),
    vec3(0.066, -0.657, -0.570),
    vec3(-0.214, 0.288, 0.188),
    vec3(-0.689, -0.222, -0.192),
    vec3(-0.008, -0.212, -0.721),
    vec3(0.053, -0.863, 0.054),
    vec3(0.639, -0.558, 0.289),
    vec3(-0.255, 0.958, 0.099),
    vec3(-0.488, 0.473, -0.381),
    vec3(-0.592, -0.332, 0.137),
    vec3(0.080, 0.756, -0.494),
    vec3(-0.638, 0.319, 0.686),
    vec3(-0.663, 0.230, -0.634),
    vec3(0.235, -0.547, 0.664),
    vec3(0.164, -0.710, 0.086),
    vec3(-0.009, 0.493, -0.038),
    vec3(-0.322, 0.147, -0.105),
    vec3(-0.554, -0.725, 0.289),
    vec3(0.534, 0.157, -0.250)
);

vec2 poissonDisk16[16] = vec2[](
    vec2(-0.7465202f, 0.4490219f),
    vec2(-0.6181046f, -0.07440206f),
    vec2(-0.1727871f, 0.003316618f),
    vec2(-0.05351699f, 0.5800206f),
    vec2(-0.4816332f, 0.7933055f),
    vec2(0.3972999f, 0.5579593f),
    vec2(0.4309787f, 0.08007714f),
    vec2(0.2419288f, -0.3548587f),
    vec2(0.5491309f, -0.6481215f),
    vec2(0.8807998f, 0.05989922f),
    vec2(0.8262667f, 0.4751753f),
    vec2(-0.3848403f, -0.5126396f),
    vec2(0.1026901f, -0.7473215f),
    vec2(-0.8397139f, -0.4312865f),
    vec2(0.145882f, 0.9274838f),
    vec2(0.88617f, -0.3436382f)
);

// FILE: 'Shader/Includes/Random.include' 
float rand(float a, float b, float c){
    return fract(sin(dot(vec3(a, b, c) ,vec3(12.9898,78.233,45.164))) * 43758.5453);
}

float rand(float a, float b){
    return fract(sin(dot(vec2(a, b) ,vec2(12.9898,78.233))) * 43758.5453);
}



#ifdef DSSDO_ENABLED

    // Store configuration variables in const variables
    // const int   dssdoSampleCount = DSSDO_NUM_SAMPLES;
    // const float dssdoRadius      = DSSDO_RADIUS;
    // const float dssdoMaxDistance = DSSDO_MAX_DISTANCE;
    // const float dssdoMaxAngle    = DSSDO_MAX_ANGLE;
    // const float dssdoFactor      = DSSDO_STRENGTH;
    const int   dssdoSampleCount = 32;
    const float dssdoRadius      = 0.5;
    const float dssdoMaxDistance = 20.0;
    const float dssdoMaxAngle    = 0.1;
    const float dssdoFactor      = 1.0;


    const int   dssdoPoissonFactor = 32 / dssdoSampleCount;
    const float fudgeFactorL0      = 2.0;
    const float fudgeFactorL1      = 10.0;
    const float sh2WeightL0        = fudgeFactorL0 * 0.28209; //0.5*sqrt(1.0/pi);
    const vec3  sh2WeightL1        = vec3(fudgeFactorL1 * 0.48860); //0.5*sqrt(3.0/pi);
    const vec4  sh2Weight          = vec4(sh2WeightL1, sh2WeightL0) / dssdoSampleCount;


    uniform sampler2D dssdoNoiseTex;

    float computeDSSDO(vec2 texcoord, ivec2 screenCoord, Material material, float dist, sampler2D normalTex, sampler2D positionTex) {

        #ifdef DEBUG_DISABLE_SSDO
            return 1.0;
        #endif

        float radius = clamp( (1.0 / dist) * 1000.0 * dssdoRadius, 0.0, 80.0);
        // radius *= 0.4;
        // radius = 20.0;

        ivec2 screenSize = textureSize(normalTex, 0) - 1;
        vec3 noise = texelFetch(dssdoNoiseTex, screenCoord % 4, 0).rgb*2.0 - 1.0;
        noise *= 0.0;

        float occlusionResult = 0.0;

        for (int i = 1; i < 32; i++) {

            vec3 offset = poisson3D_32[i * dssdoPoissonFactor];

            ivec2 offsetCoord = screenCoord +
                ivec2(reflect(poisson3D_32[i].xy, noise.xy) * radius);

            offsetCoord = clamp(offsetCoord, ivec2(0), screenSize);

            vec3 position = texelFetch(positionTex, offsetCoord, 0).rgb;

            vec3 difference = (position - material.position);

            float differenceLength = length(difference);

            vec3 differenceNormalized = difference / max(1.0, differenceLength);

            float attenuation = 1.0 - saturate(
                differenceLength / dssdoMaxDistance );

            float dotProduct = max(0.0, dot(material.normal, differenceNormalized) );

            attenuation = attenuation * attenuation * step(dssdoMaxAngle, dotProduct);
            // attenuation = attenuation * attenuation;

            // attenuation = pow(differenceNormalized.x * 2.0, 10.0);

            occlusionResult += attenuation / float(dssdoSampleCount);
            // occlusionResult += attenuation / 1.0;

            // occlusionResult += abs(material.normal.y);

        }

        occlusionResult = 1.0 - max(0.0, occlusionResult * dssdoFactor);
        return saturate(occlusionResult);
    }

#else

    float computeDSSDO(vec2 texcoord, ivec2 screenCoord, Material material, float dist, sampler2D normalTex, sampler2D positionTex) {
        return 1.0;
    }


#endif

uniform sampler2D data0;
uniform sampler2D data1;
uniform sampler2D data2;

layout (r32i) readonly uniform iimage2D lightsPerTile;
layout (rgba16f) uniform image2D destination;


uniform Light lights[MAX_VISIBLE_LIGHTS];
uniform ShadowSource shadowSources[SHADOW_MAX_TOTAL_MAPS];
in vec2 texcoord;

uniform int temporalProjXOffs;

// Has to be after the uniforms

// FILE: 'Shader/Includes/Lighting.include' 
// FILE: 'Shader/Includes/LightingModels.include' 
// Lighting variables
const float rho = 2.0;
const float sigma = 10.0;
const float PI = 3.14159265358979323846;
const float DIRECTIONAL_LIGHT_SIZE = 9999999999999.0;



float safeDot(vec3 a, vec3 b) {
    return max(0.0, dot(a, b));
}



vec3 specularBrdfFresnel(vec3 f0, float u)
{
    // from Schlick
    return f0 + (1-f0) * pow(1-u, 5);
}

float specularBrdfD(vec3 n, vec3 h, float roughness) {
    return (roughness * roughness) / (
        PI * pow(
            pow(dot(n, h), 2.0) *
            ( (roughness * roughness) - 1.0 ) + 1 , 2.0)
        );
}



float specularGGetK(float a) {
    return pow(0.8 + 0.5 * a, 2.0) * 0.5;
}

float specularBrdfGSub(vec3 v, vec3 n, float roughness) {
    float nDotV = safeDot(n, v);
    return nDotV / ( nDotV * (1.0-roughness) + roughness );
}

float specularBrdfG(vec3 l, vec3 v, vec3 h, vec3 n, float roughness) {
    float k = specularGGetK(roughness);
    return specularBrdfGSub(l, n, k) * specularBrdfGSub(v, n, k);
}




vec3 diffuseBrdfOrenNayar( vec3 L, vec3 V, vec3 N )
{
    float VdotN = safeDot(V,N);
    float LdotN = safeDot(L,N);
    float theta_r = acos (VdotN);
    float sigma2 = pow(sigma*PI/180,2);


    float cos_phi_diff = dot( normalize(V-N*(VdotN)), normalize(L - N*(LdotN)) );
    float theta_i = acos (LdotN);
    float alpha = max (theta_i, theta_r);
    float beta = min (theta_i, theta_r);

    // if (alpha > PI/2) return vec3(0);
    // return vec3(alpha);

    float C1 = 1 - 0.5 * sigma2 / (sigma2 + 0.33);
    float C2 = 0.45 * sigma2 / (sigma2 + 0.09);
    if (cos_phi_diff >= 0) C2 *= sin(alpha);
    else C2 *= (sin(alpha) - pow(2*beta/PI,3));

    float C3 = 0.125 * sigma2 / (sigma2+0.09) * pow ((4*alpha*beta)/(PI*PI),2);
    float L1 = rho/PI * (C1 + cos_phi_diff * C2 * tan(beta) + (1 - abs(cos_phi_diff)) * C3 * tan((alpha+beta)/2));
    float L2 = 0.17 * rho*rho / PI * sigma2/(sigma2+0.13) * (1 - cos_phi_diff*(4*beta*beta)/(PI*PI));
    return vec3(L1 + L2);
}


// Simpler version of oren nayar which computes a lot faster
float diffuseBrdfSimpleOrenNayar( vec3 l, vec3 v, vec3 n, float roughness) {
    // calculate intermediary values
    float NdotL = dot(n, l);
    float NdotV = dot(n, v);

    float angleVN = acos(NdotV);
    float angleLN = acos(NdotL);

    float alpha = max(angleVN, angleLN);
    float beta = min(angleVN, angleLN);
    float gamma = dot(v - n * NdotV, l - n * NdotL);

    float roughnessSquared = roughness * roughness;

    // calculate A and B
    float A = 1.0 - 0.5 * (roughnessSquared / (roughnessSquared + 0.57));

    float B = 0.45 * (roughnessSquared / (roughnessSquared + 0.09));

    float C = sin(alpha) * tan(beta);

    // put it all together
    float L1 = max(0.0, NdotL) * (A + B * max(0.0, gamma) * C);
    return L1;

}

// FILE: 'Shader/Includes/ParabolicTransform.include' 
vec4 transformParabol(vec4 transformed, float near, float far) {
    // return transformed;

    if (transformed.w < 0.0) return vec4(0,0,0,-1000);

    // float l = length(transformed.xyz);
    float l = length(transformed.xyz);
    // float l = transformed.z;
    // transformed = length(trans);

    transformed /= l;


    transformed.z += 1;
    transformed.xy /= transformed.z;

    transformed.z = (l - near) / (far - near);
    // transformed = normalize(transformed);
    transformed.w = 1;


    // float l = length(transformed.xyz);
    // transformed = transformed/l;
    // // transformed = normalize(transformed);

    // transformed.z = transformed.z + 1;
    // transformed.z = (l - near)/(far-near);
    // transformed.w = 1;
    return transformed;
}

// FILE: 'Shader/Includes/PositionReconstruction.include' 
uniform mat4 trans_clip_of_mainCam_to_mainRender;


const float ndcNear = 0.1;
const float ndcFar = 30000.0;
const float ndcA = ndcNear + ndcFar;
const float ndcB = ndcNear - ndcFar;
const float ndcC = 2.0 * ndcNear * ndcFar;
const float ndcD = ndcFar - ndcNear;

float getZFromNdc(vec3 ndcPos) {
  float d = ndcPos.z * ndcB;
  return (ndcC / (ndcA+d));
}


// z has to be in range 0..MAIN_CAMERA_FAR
float getZFromLinearZ(float z) {

    //((((1.0 / (z / ndcC)) - ndcA) / ndcB) / 2.0) + 0.5;

  z /= ndcC;
  z = 1.0 / z;
  z -= ndcA;
  z /= ndcB;
  z /= 2.0;
  z += 0.5;
  return z;
}

float getLinearZFromZ(float z) {
    float z_n = z * 2.0 - 1.0;
    float z_e = ndcC / (ndcA - z_n * ndcD);
    return z_e;
}

float getCustomLinearZFromZ(float z, float near, float far) {
    float z_n = z * 2.0 - 1.0;
    float z_e = 2.0 * near * far / (far + near - z_n * (far - near));
    return z_e;
}

float normalizeZ(float z, float near, float far) {
  return getCustomLinearZFromZ(z, near, far) / far;
}




vec3 calculateSurfacePos(float z, vec2 tcoord) {

  vec3 ndcPos = vec3(tcoord.xy, z)*2.0 - 1.0;
  // ndcPos.xyz -= 0.5;
  // ndcPos.xyz *= 2.0;

  vec4 clipPos = vec4(0);
  clipPos.w = getZFromNdc(ndcPos);

  clipPos.xyz = ndcPos * clipPos.w;

  vec3 surfacePosition = (trans_clip_of_mainCam_to_mainRender * clipPos).xyz;
  return surfacePosition;
}

uniform vec3 cameraPosition;
uniform samplerCube fallbackCubemap;

const mat4 shadowBiasMatrix = mat4(
    0.5, 0.0, 0.0, 0.0,
    0.0, 0.5, 0.0, 0.0,
    0.0, 0.0, 0.5, 0.0,
    0.5, 0.5, 0.5, 1.0
);


#if USE_HARDWARE_PCF
    uniform sampler2DShadow shadowAtlas;
#else
    uniform sampler2D shadowAtlas;
#endif





vec2 convertAtlasCoord(vec2 rawCoord, ShadowSource source) {

    float factor = float(source.resolution) / SHADOW_MAP_ATLAS_SIZE;
    float factorBy1 = 1.0 / SHADOW_MAP_ATLAS_SIZE;
    return ( clamp(rawCoord * factor, factorBy1, 1.0 - factorBy1) + source.atlasPos);
}



vec3 computeLightModel(Light light, Material material, vec3 l, vec3 v, vec3 n, vec3 h, float attenuation) {

    #if USE_SIMPLE_LIGHTING

        // return max(vec3(0.0), light.color * attenuation * dot(n, l));
        return light.color * attenuation;

    #else
        float roughness = clamp(material.roughness, 0.005, 1.0);
        float specular = material.specular;
        float refractiveFactor = material.metallic * 0.5 + 0.5;

        vec3 diffuseColor = material.baseColor * (1.0 - material.metallic);
        vec3 specularColor = material.baseColor * (material.metallic) + specular * (1.0 - material.metallic);

        // Compute reflection
        vec3 reflectedDir = reflect( v, n);

        float cubemapResolutionParameter = material.roughness;
        vec3 reflection1 = textureLod(fallbackCubemap, reflectedDir.xzy, cubemapResolutionParameter * 10.0).rgb;
        vec3 reflection2 = textureLod(fallbackCubemap, reflectedDir.xzy, cubemapResolutionParameter * 10.0 - 1.0).rgb;
        vec3 reflectedColor = reflection1*0.5 + reflection2*0.5;

        // Compute specular BRDF
        float specG = clamp(specularBrdfG(l, v, h, n, roughness), 0, 1);
        vec3  specF = clamp(specularBrdfFresnel(specularColor, safeDot(v, n)  ) , 0, 1);

        // D is not clamped, highlights can get very bright
        float specD = specularBrdfD(n, h, roughness);

        // Compute diffuse BRDF
        // vec3 diffuseBrdf = diffuseBrdfOrenNayar(l, v, n) * safeDot(n, l);
        vec3 diffuseBrdf = vec3(diffuseBrdfSimpleOrenNayar(l, v, n, 1.5));

        // Combine specular
        vec3 specularTerm = (specF * specG * specD) * max(0.0, 4.0 * dot(n, l) * dot(n, v));

        // Compute total contributions
        vec3 diffuseContribution = diffuseColor * diffuseBrdf * attenuation * light.color;
        vec3 specularContribution = specularTerm * attenuation * light.color * specular;
        vec3 refractiveContribution = reflectedColor * refractiveFactor * specularColor * specF * attenuation * light.color * safeDot(n, l);


        vec3 combinedContribution = refractiveContribution + diffuseContribution + specularContribution;
        return max(vec3(0.0), combinedContribution);

    #endif


}


float getRandom(vec2 seed) {
    float dot_product = dot(seed, vec2(12.9898,78.233));
    return fract(sin(dot_product) * 43758.5453);
}


float computePointLightAttenuation(Light light, float distanceToLight) {
    float attenuation = pow(1.0 + (distanceToLight / light.radius) , -2.0) * 1.2;

    // Cut light transition starting at 80%. Otherwise it's exponential and never gets really 0
    float cutoff = light.radius * 0.8;
    attenuation *= 1.0 - smoothstep(0.0, 1.0, ( (distanceToLight / cutoff) - 1.0) * 4.0 );
    attenuation = max(0.0, attenuation);

    return attenuation;
}

vec3 applyPointLight(Light light, Material material) {

    float distanceToLight = distance(material.position, light.position);
    float distanceRelative = distanceToLight / light.radius;
    float attenuation = computePointLightAttenuation(light, distanceToLight);

    vec3  l = normalize(light.position - material.position);
    vec3  v = normalize(cameraPosition - material.position);
    vec3  n = normalize(material.normal);
    vec3  h = normalize(l + v);

    return computeLightModel(light, material, l,v, n, h, attenuation);
}


vec3 applyPointLightWithShadow(Light light, Material material) {

    float distanceToLight = distance(material.position, light.position);
    float distanceRelative = distanceToLight / light.radius;
    float attenuation = computePointLightAttenuation(light, distanceToLight);

    vec3  l = normalize(light.position - material.position);
    vec3  v = normalize(cameraPosition - material.position);
    vec3  n = normalize(material.normal);
    vec3  h = normalize(l + v);


    vec3 rawLighting = computeLightModel(light, material, l,v, n, h, attenuation);

    // apply point light shadows
    float shadowFactor = 0.0;

    // For point lights we can decide by position which shadow map to use
    int shadowIndex = int(step(light.position.y, material.position.y));
    int shadowSourceIndex = light.sourceIndexes[shadowIndex];

    ShadowSource currentSource = shadowSources[shadowSourceIndex];

    float resolutionFactor = SHADOW_MAP_ATLAS_SIZE / float(currentSource.resolution);
    float sampleFactor = 1.0 / SHADOW_MAP_ATLAS_SIZE;




    vec4 projected = currentSource.mvp * vec4(material.position, 1);
    projected = transformParabol(projected, currentSource.nearPlane, currentSource.farPlane);
    projected = projected * 0.5 + 0.5;
    vec3 projCoord = projected.xyz / projected.w;
    vec2 centerCoord = convertAtlasCoord(projCoord.xy, currentSource);

    float pixOffset = 1.0 / SHADOW_MAP_ATLAS_SIZE;



    float cosTheta = clamp( dot(n, l), 0.0, 1.0 );
    float bias = 0.0013*(0.0+distanceRelative*1.0)*tan(acos(cosTheta)) / resolutionFactor;
    bias = 0.002;
    bias = clamp(bias, -0.0, 0.04);

    // http://homepage.cs.uiowa.edu/~dou/Paper/Adaptive_Depth_Bias_for_Shadow_Maps.pdf
    float l_f = currentSource.farPlane;
    float l_n = currentSource.nearPlane;

    float sceneScale = 1.0;
    float K = 0.0001;

    // (lf − depth × (lf − ln))²
    float epsilon = pow(l_f - distanceRelative * (l_f - l_n), 2.0);

    // lf × ln × (lf − ln)
    epsilon /= l_f * l_n * (l_f - l_n);

    // × sceneScale × K
    epsilon = distanceRelative * sceneScale * K;

    // bias = 0;

    // bias = 0.0 * tan(acos(dot(n,l)));


    for (int i = 0; i < SHADOWS_NUM_SAMPLES; i++) {

        vec2 offset = poissonDisk16[i] * pixOffset;
        // offset *= 0.0;r

        #if USE_HARDWARE_PCF
            float sampled = texture(shadowAtlas, vec3(centerCoord + offset, projCoord.z - bias) ).r;
            // sampled = sampled*sampled;
            shadowFactor += (1.0 - sampled) / SHADOWS_NUM_SAMPLES;
        #else
            float sampled = textureLod(shadowAtlas, centerCoord + offset , 0).r;
            shadowFactor += step(sampled, projCoord.z - bias) / SHADOWS_NUM_SAMPLES;
            // shadowFactor = sampled - projCoord.z;

        #endif
    }

    // shadowFactor *= 16.0;

    // return vec3( abs(nearestBlocker-centerCoord) * 24.0, 0);
    // shadowFactor = nearestPointDepth * 100000.0;

    // Apply shadows
    rawLighting *= max(0.001, 1.0 - shadowFactor);

    // return vec3(1.0 - shadowFactor) * attenuation;

    // return vec3( 1.0 - shadowFactor );

    // return 1.0 - vec3(pow(shadowFactor, 20.0) * 1000.0) * attenuation;

    return max(vec3(0.0), rawLighting);
}




#if 0


#endif

out vec4 lightingResult;

void main() {


    // Compute texcoords
    ivec2 screenSize = textureSize(data0, 0);
    ivec2 screenCoord = ivec2(texcoord * vec2(screenSize.x + 1 , screenSize.y));

    // Shift x by 1 for temporal reprojection
    // Usually we would do just screenCoord.x += temporalProjXOffs
    // But using a checkerboard pattern removes a lot of artifacts,
    // as you otherwise can see the line-pattern very obviously. Using
    // a checkerboard more gives a dithering effect, which is barely visible
    screenCoord.x += (screenCoord.x + screenCoord.y) % 2 == temporalProjXOffs ? -1 : 0;

    ivec2 precomputeCoord = ivec2( vec2(screenCoord) /
        vec2(LIGHTING_COMPUTE_PATCH_SIZE_X, LIGHTING_COMPUTE_PATCH_SIZE_Y) ) * 8;


    // Extract material data
    vec4 target0data = texelFetch(data0, screenCoord, 0);
    vec4 target1data = texelFetch(data1, screenCoord, 0);
    vec4 target2data = texelFetch(data2, screenCoord, 0);
    Material material = unpackMaterial(target0data, target1data, target2data);

    // Fetch the light counts
    // We perform a min as it *might* be that we read a wrong value
    // from the texture. Imagine reading 123123123 from the texture,
    // then the light processing loop would be 123123123 iterations long,
    // which simply crashes the driver. With this method it would be only
    // a few hundreds, which is long but does not crash the driver.
    int countPointLight = min(MAX_POINT_LIGHTS,
        imageLoad(lightsPerTile, precomputeCoord + ivec2(0,0)).r);

    int countPointLightShadow = min(MAX_SHADOW_POINT_LIGHTS,
        imageLoad(lightsPerTile, precomputeCoord + ivec2(1,0)).r);


    vec3 result = vec3(0);

    // Compute point lights
    ivec2 baseOffset = precomputeCoord + ivec2(0,1);
    ivec2 currentOffset = ivec2(0);
    int currentLightId = 0;
    Light currentLight;

    for (int i = 0; i < countPointLight; i++) {
        currentOffset = ivec2(i % 8, i / 8);
        currentLightId = imageLoad(lightsPerTile, baseOffset + currentOffset).r;
        currentLight = lights[currentLightId];

        result += applyPointLight(currentLight, material);
    }

    // Compute shadow point lights
    baseOffset = precomputeCoord + ivec2(0,3);
    for (int i = 0; i < countPointLightShadow; i++) {
        currentOffset = ivec2(i % 8, i / 8);
        currentLightId = imageLoad(lightsPerTile, baseOffset + currentOffset).r;
        currentLight = lights[currentLightId];

        #if USE_SHADOWS
            result += applyPointLightWithShadow(currentLight, material);
        #else:
            result += applyPointLight(currentLight, material);
        #endif
    }

    // Now, compute rOcclusion
    float distanceToCamera = distance(cameraPosition, material.position);
    float occlusionFactor = computeDSSDO(texcoord,screenCoord, material, distanceToCamera, data1, data0);

    // Metallic materials don't have much occlusion
    // occlusionFactor = mix(occlusionFactor, 1.0, saturate(material.metallic-1.0) );
    // occlusionFactor = 1.0;

    // Visualize lights per tile
    // float processed = float(countPointLight + countPointLightShadow) / 5.0;
    // vec3 processedColor = vec3(processed, 1.0 - processed ,0);
    // result = mix(result, processedColor, 0.5);

    // result = vec3(material.baseColor);

    #ifdef DSSDO_ONLY
        result.xyz = vec3(1);
    #endif

    // Special debug rendermodes

    #ifdef DEBUG_RM_BASECOLOR
        result = material.baseColor;
    #endif

    #ifdef DEBUG_RM_SPECULAR
        result = vec3(material.specular);
    #endif

    #ifdef DEBUG_RM_SSDO
        result = vec3(1);
    #endif

    #ifdef DEBUG_RM_METALLIC
        result = vec3(material.metallic);
    #endif

    #ifdef DEBUG_RM_ROUGHNESS
        result = vec3(material.roughness);
    #endif

    #ifdef DEBUG_RM_NORMAL
        result = vec3(material.normal);
    #endif


    // HDR Mapping
    result.xyz = 1.0f - exp(-1.0 * result.xyz);

    // SRGB
    result.xyz = sqrt(result.xyz);

    // result = vec3(material.normal);

    lightingResult = vec4(result, occlusionFactor);
}
